{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.984301412872842,
  "eval_steps": 500,
  "global_step": 1590,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06279434850863422,
      "grad_norm": 12.211408615112305,
      "learning_rate": 6.289308176100629e-06,
      "loss": 0.9621,
      "step": 10
    },
    {
      "epoch": 0.12558869701726844,
      "grad_norm": 5.938352584838867,
      "learning_rate": 1.2578616352201259e-05,
      "loss": 0.8047,
      "step": 20
    },
    {
      "epoch": 0.18838304552590268,
      "grad_norm": 3.319908380508423,
      "learning_rate": 1.8867924528301888e-05,
      "loss": 0.6701,
      "step": 30
    },
    {
      "epoch": 0.25117739403453687,
      "grad_norm": 3.1339070796966553,
      "learning_rate": 2.5157232704402517e-05,
      "loss": 0.5079,
      "step": 40
    },
    {
      "epoch": 0.3139717425431711,
      "grad_norm": 2.4518778324127197,
      "learning_rate": 3.144654088050314e-05,
      "loss": 0.4595,
      "step": 50
    },
    {
      "epoch": 0.37676609105180536,
      "grad_norm": 3.9446208477020264,
      "learning_rate": 3.7735849056603776e-05,
      "loss": 0.3898,
      "step": 60
    },
    {
      "epoch": 0.43956043956043955,
      "grad_norm": 6.282701015472412,
      "learning_rate": 4.402515723270441e-05,
      "loss": 0.4003,
      "step": 70
    },
    {
      "epoch": 0.5023547880690737,
      "grad_norm": 9.076297760009766,
      "learning_rate": 5.0314465408805034e-05,
      "loss": 0.4303,
      "step": 80
    },
    {
      "epoch": 0.565149136577708,
      "grad_norm": 6.2733259201049805,
      "learning_rate": 5.660377358490566e-05,
      "loss": 0.3833,
      "step": 90
    },
    {
      "epoch": 0.6279434850863422,
      "grad_norm": 4.042316913604736,
      "learning_rate": 6.289308176100629e-05,
      "loss": 0.3366,
      "step": 100
    },
    {
      "epoch": 0.6907378335949764,
      "grad_norm": 7.292440891265869,
      "learning_rate": 6.918238993710691e-05,
      "loss": 0.4032,
      "step": 110
    },
    {
      "epoch": 0.7535321821036107,
      "grad_norm": 3.867114543914795,
      "learning_rate": 7.547169811320755e-05,
      "loss": 0.3815,
      "step": 120
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 3.2105672359466553,
      "learning_rate": 8.176100628930818e-05,
      "loss": 0.3682,
      "step": 130
    },
    {
      "epoch": 0.8791208791208791,
      "grad_norm": 4.69343900680542,
      "learning_rate": 8.805031446540882e-05,
      "loss": 0.3374,
      "step": 140
    },
    {
      "epoch": 0.9419152276295133,
      "grad_norm": 1.792950987815857,
      "learning_rate": 9.433962264150944e-05,
      "loss": 0.3256,
      "step": 150
    },
    {
      "epoch": 1.0047095761381475,
      "grad_norm": 2.3583335876464844,
      "learning_rate": 9.999987950741765e-05,
      "loss": 0.2964,
      "step": 160
    },
    {
      "epoch": 1.0675039246467817,
      "grad_norm": 2.325028419494629,
      "learning_rate": 9.9985421100216e-05,
      "loss": 0.3348,
      "step": 170
    },
    {
      "epoch": 1.130298273155416,
      "grad_norm": 3.3881795406341553,
      "learning_rate": 9.99468721610658e-05,
      "loss": 0.2895,
      "step": 180
    },
    {
      "epoch": 1.1930926216640503,
      "grad_norm": 2.5336389541625977,
      "learning_rate": 9.988425126867315e-05,
      "loss": 0.3152,
      "step": 190
    },
    {
      "epoch": 1.2558869701726845,
      "grad_norm": 7.657009601593018,
      "learning_rate": 9.979758860325019e-05,
      "loss": 0.2889,
      "step": 200
    },
    {
      "epoch": 1.3186813186813187,
      "grad_norm": 1.650239109992981,
      "learning_rate": 9.968692593196944e-05,
      "loss": 0.3745,
      "step": 210
    },
    {
      "epoch": 1.3814756671899528,
      "grad_norm": 3.172187328338623,
      "learning_rate": 9.955231658883432e-05,
      "loss": 0.2587,
      "step": 220
    },
    {
      "epoch": 1.4442700156985873,
      "grad_norm": 1.8967193365097046,
      "learning_rate": 9.93938254489746e-05,
      "loss": 0.329,
      "step": 230
    },
    {
      "epoch": 1.5070643642072215,
      "grad_norm": 1.5402942895889282,
      "learning_rate": 9.921152889737984e-05,
      "loss": 0.2219,
      "step": 240
    },
    {
      "epoch": 1.5698587127158556,
      "grad_norm": 1.9615978002548218,
      "learning_rate": 9.900551479208552e-05,
      "loss": 0.2406,
      "step": 250
    },
    {
      "epoch": 1.6326530612244898,
      "grad_norm": 2.855955123901367,
      "learning_rate": 9.877588242182975e-05,
      "loss": 0.2546,
      "step": 260
    },
    {
      "epoch": 1.695447409733124,
      "grad_norm": 2.5028159618377686,
      "learning_rate": 9.852274245820096e-05,
      "loss": 0.2261,
      "step": 270
    },
    {
      "epoch": 1.7582417582417582,
      "grad_norm": 1.446355938911438,
      "learning_rate": 9.824621690229965e-05,
      "loss": 0.2596,
      "step": 280
    },
    {
      "epoch": 1.8210361067503924,
      "grad_norm": 1.6450074911117554,
      "learning_rate": 9.79464390259397e-05,
      "loss": 0.2402,
      "step": 290
    },
    {
      "epoch": 1.8838304552590266,
      "grad_norm": 5.6638407707214355,
      "learning_rate": 9.762355330741796e-05,
      "loss": 0.2239,
      "step": 300
    },
    {
      "epoch": 1.9466248037676608,
      "grad_norm": 1.9204989671707153,
      "learning_rate": 9.727771536188275e-05,
      "loss": 0.2395,
      "step": 310
    },
    {
      "epoch": 2.009419152276295,
      "grad_norm": 1.032841444015503,
      "learning_rate": 9.690909186633492e-05,
      "loss": 0.2124,
      "step": 320
    },
    {
      "epoch": 2.072213500784929,
      "grad_norm": 1.617019772529602,
      "learning_rate": 9.651786047929773e-05,
      "loss": 0.1416,
      "step": 330
    },
    {
      "epoch": 2.1350078492935634,
      "grad_norm": 3.4484643936157227,
      "learning_rate": 9.610420975519408e-05,
      "loss": 0.1636,
      "step": 340
    },
    {
      "epoch": 2.197802197802198,
      "grad_norm": 1.5811679363250732,
      "learning_rate": 9.566833905347245e-05,
      "loss": 0.1527,
      "step": 350
    },
    {
      "epoch": 2.260596546310832,
      "grad_norm": 2.843571901321411,
      "learning_rate": 9.521045844252552e-05,
      "loss": 0.1567,
      "step": 360
    },
    {
      "epoch": 2.3233908948194664,
      "grad_norm": 2.2245540618896484,
      "learning_rate": 9.473078859844728e-05,
      "loss": 0.1317,
      "step": 370
    },
    {
      "epoch": 2.3861852433281006,
      "grad_norm": 3.932750940322876,
      "learning_rate": 9.422956069867807e-05,
      "loss": 0.1671,
      "step": 380
    },
    {
      "epoch": 2.4489795918367347,
      "grad_norm": 6.276426792144775,
      "learning_rate": 9.370701631058829e-05,
      "loss": 0.169,
      "step": 390
    },
    {
      "epoch": 2.511773940345369,
      "grad_norm": 4.923506259918213,
      "learning_rate": 9.316340727505468e-05,
      "loss": 0.1748,
      "step": 400
    },
    {
      "epoch": 2.574568288854003,
      "grad_norm": 1.038479208946228,
      "learning_rate": 9.259899558508543e-05,
      "loss": 0.1663,
      "step": 410
    },
    {
      "epoch": 2.6373626373626373,
      "grad_norm": 4.035729885101318,
      "learning_rate": 9.201405325955221e-05,
      "loss": 0.1012,
      "step": 420
    },
    {
      "epoch": 2.7001569858712715,
      "grad_norm": 1.8305810689926147,
      "learning_rate": 9.14088622120905e-05,
      "loss": 0.234,
      "step": 430
    },
    {
      "epoch": 2.7629513343799057,
      "grad_norm": 1.702803134918213,
      "learning_rate": 9.078371411523084e-05,
      "loss": 0.112,
      "step": 440
    },
    {
      "epoch": 2.82574568288854,
      "grad_norm": 2.0871496200561523,
      "learning_rate": 9.013891025982704e-05,
      "loss": 0.1726,
      "step": 450
    },
    {
      "epoch": 2.8885400313971745,
      "grad_norm": 1.5531229972839355,
      "learning_rate": 8.947476140984856e-05,
      "loss": 0.1263,
      "step": 460
    },
    {
      "epoch": 2.9513343799058083,
      "grad_norm": 2.3874154090881348,
      "learning_rate": 8.879158765260767e-05,
      "loss": 0.1398,
      "step": 470
    },
    {
      "epoch": 3.014128728414443,
      "grad_norm": 2.0368354320526123,
      "learning_rate": 8.808971824449275e-05,
      "loss": 0.0886,
      "step": 480
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 4.2776360511779785,
      "learning_rate": 8.736949145228295e-05,
      "loss": 0.0991,
      "step": 490
    },
    {
      "epoch": 3.1397174254317113,
      "grad_norm": 3.0230746269226074,
      "learning_rate": 8.66312543901201e-05,
      "loss": 0.0819,
      "step": 500
    },
    {
      "epoch": 3.1397174254317113,
      "eval_loss": 0.19906726479530334,
      "eval_runtime": 4.2507,
      "eval_samples_per_second": 12.233,
      "eval_steps_per_second": 12.233,
      "step": 500
    },
    {
      "epoch": 3.2025117739403455,
      "grad_norm": 5.252191543579102,
      "learning_rate": 8.587536285221656e-05,
      "loss": 0.0801,
      "step": 510
    },
    {
      "epoch": 3.2653061224489797,
      "grad_norm": 3.729785680770874,
      "learning_rate": 8.510218114137992e-05,
      "loss": 0.0899,
      "step": 520
    },
    {
      "epoch": 3.328100470957614,
      "grad_norm": 1.877109408378601,
      "learning_rate": 8.43120818934367e-05,
      "loss": 0.0758,
      "step": 530
    },
    {
      "epoch": 3.390894819466248,
      "grad_norm": 3.0158748626708984,
      "learning_rate": 8.350544589764016e-05,
      "loss": 0.0907,
      "step": 540
    },
    {
      "epoch": 3.4536891679748822,
      "grad_norm": 1.606440544128418,
      "learning_rate": 8.268266191314848e-05,
      "loss": 0.1032,
      "step": 550
    },
    {
      "epoch": 3.5164835164835164,
      "grad_norm": 0.859740138053894,
      "learning_rate": 8.184412648166183e-05,
      "loss": 0.0626,
      "step": 560
    },
    {
      "epoch": 3.5792778649921506,
      "grad_norm": 1.6806527376174927,
      "learning_rate": 8.099024373630854e-05,
      "loss": 0.0515,
      "step": 570
    },
    {
      "epoch": 3.642072213500785,
      "grad_norm": 2.396972894668579,
      "learning_rate": 8.01214252068728e-05,
      "loss": 0.0813,
      "step": 580
    },
    {
      "epoch": 3.704866562009419,
      "grad_norm": 0.173788920044899,
      "learning_rate": 7.923808962145734e-05,
      "loss": 0.0451,
      "step": 590
    },
    {
      "epoch": 3.767660910518053,
      "grad_norm": 2.089458465576172,
      "learning_rate": 7.83406627046769e-05,
      "loss": 0.077,
      "step": 600
    },
    {
      "epoch": 3.830455259026688,
      "grad_norm": 2.1175923347473145,
      "learning_rate": 7.742957697247984e-05,
      "loss": 0.082,
      "step": 610
    },
    {
      "epoch": 3.8932496075353216,
      "grad_norm": 3.799797296524048,
      "learning_rate": 7.650527152369647e-05,
      "loss": 0.0599,
      "step": 620
    },
    {
      "epoch": 3.956043956043956,
      "grad_norm": 1.7064765691757202,
      "learning_rate": 7.556819182841497e-05,
      "loss": 0.084,
      "step": 630
    },
    {
      "epoch": 4.01883830455259,
      "grad_norm": 3.92333722114563,
      "learning_rate": 7.461878951328653e-05,
      "loss": 0.0415,
      "step": 640
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 4.9916534423828125,
      "learning_rate": 7.365752214386321e-05,
      "loss": 0.032,
      "step": 650
    },
    {
      "epoch": 4.144427001569858,
      "grad_norm": 1.7758511304855347,
      "learning_rate": 7.268485300407393e-05,
      "loss": 0.0245,
      "step": 660
    },
    {
      "epoch": 4.207221350078493,
      "grad_norm": 2.1779024600982666,
      "learning_rate": 7.17012508729441e-05,
      "loss": 0.0368,
      "step": 670
    },
    {
      "epoch": 4.270015698587127,
      "grad_norm": 0.5684669613838196,
      "learning_rate": 7.070718979866702e-05,
      "loss": 0.0386,
      "step": 680
    },
    {
      "epoch": 4.332810047095761,
      "grad_norm": 1.1425310373306274,
      "learning_rate": 6.970314887013584e-05,
      "loss": 0.0341,
      "step": 690
    },
    {
      "epoch": 4.395604395604396,
      "grad_norm": 2.566415786743164,
      "learning_rate": 6.868961198604611e-05,
      "loss": 0.0435,
      "step": 700
    },
    {
      "epoch": 4.45839874411303,
      "grad_norm": 3.087256908416748,
      "learning_rate": 6.766706762168022e-05,
      "loss": 0.0518,
      "step": 710
    },
    {
      "epoch": 4.521193092621664,
      "grad_norm": 6.439590930938721,
      "learning_rate": 6.663600859348616e-05,
      "loss": 0.1152,
      "step": 720
    },
    {
      "epoch": 4.583987441130298,
      "grad_norm": 1.1076775789260864,
      "learning_rate": 6.55969318215641e-05,
      "loss": 0.0307,
      "step": 730
    },
    {
      "epoch": 4.646781789638933,
      "grad_norm": 0.2855251133441925,
      "learning_rate": 6.455033809017512e-05,
      "loss": 0.0377,
      "step": 740
    },
    {
      "epoch": 4.7095761381475665,
      "grad_norm": 0.5988145470619202,
      "learning_rate": 6.34967318063877e-05,
      "loss": 0.0683,
      "step": 750
    },
    {
      "epoch": 4.772370486656201,
      "grad_norm": 0.8594285249710083,
      "learning_rate": 6.24366207569781e-05,
      "loss": 0.0493,
      "step": 760
    },
    {
      "epoch": 4.835164835164835,
      "grad_norm": 1.2815632820129395,
      "learning_rate": 6.137051586370194e-05,
      "loss": 0.0295,
      "step": 770
    },
    {
      "epoch": 4.8979591836734695,
      "grad_norm": 2.682187557220459,
      "learning_rate": 6.029893093705492e-05,
      "loss": 0.0299,
      "step": 780
    },
    {
      "epoch": 4.960753532182103,
      "grad_norm": 1.2960740327835083,
      "learning_rate": 5.9222382428641174e-05,
      "loss": 0.0264,
      "step": 790
    },
    {
      "epoch": 5.023547880690738,
      "grad_norm": 1.8090225458145142,
      "learning_rate": 5.814138918226887e-05,
      "loss": 0.0635,
      "step": 800
    },
    {
      "epoch": 5.086342229199372,
      "grad_norm": 1.6525359153747559,
      "learning_rate": 5.7056472183892806e-05,
      "loss": 0.0171,
      "step": 810
    },
    {
      "epoch": 5.149136577708006,
      "grad_norm": 2.4581117630004883,
      "learning_rate": 5.5968154310524614e-05,
      "loss": 0.0181,
      "step": 820
    },
    {
      "epoch": 5.211930926216641,
      "grad_norm": 0.15828704833984375,
      "learning_rate": 5.487696007823161e-05,
      "loss": 0.0242,
      "step": 830
    },
    {
      "epoch": 5.274725274725275,
      "grad_norm": 0.36241617798805237,
      "learning_rate": 5.378341538934566e-05,
      "loss": 0.0221,
      "step": 840
    },
    {
      "epoch": 5.337519623233909,
      "grad_norm": 1.5534127950668335,
      "learning_rate": 5.268804727900391e-05,
      "loss": 0.0348,
      "step": 850
    },
    {
      "epoch": 5.400313971742543,
      "grad_norm": 0.4006355106830597,
      "learning_rate": 5.159138366114358e-05,
      "loss": 0.0213,
      "step": 860
    },
    {
      "epoch": 5.463108320251178,
      "grad_norm": 4.634326457977295,
      "learning_rate": 5.049395307407329e-05,
      "loss": 0.0177,
      "step": 870
    },
    {
      "epoch": 5.525902668759811,
      "grad_norm": 3.2624828815460205,
      "learning_rate": 4.9396284425743326e-05,
      "loss": 0.0146,
      "step": 880
    },
    {
      "epoch": 5.588697017268446,
      "grad_norm": 0.15359699726104736,
      "learning_rate": 4.829890673883792e-05,
      "loss": 0.0317,
      "step": 890
    },
    {
      "epoch": 5.65149136577708,
      "grad_norm": 1.0245431661605835,
      "learning_rate": 4.7202348895812035e-05,
      "loss": 0.0059,
      "step": 900
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 4.036375045776367,
      "learning_rate": 4.610713938399601e-05,
      "loss": 0.0071,
      "step": 910
    },
    {
      "epoch": 5.777080062794348,
      "grad_norm": 3.530665874481201,
      "learning_rate": 4.5013806040890294e-05,
      "loss": 0.0175,
      "step": 920
    },
    {
      "epoch": 5.839874411302983,
      "grad_norm": 0.17652015388011932,
      "learning_rate": 4.392287579977374e-05,
      "loss": 0.0207,
      "step": 930
    },
    {
      "epoch": 5.9026687598116165,
      "grad_norm": 2.685943126678467,
      "learning_rate": 4.2834874435747305e-05,
      "loss": 0.0073,
      "step": 940
    },
    {
      "epoch": 5.965463108320251,
      "grad_norm": 5.634771823883057,
      "learning_rate": 4.1750326312336254e-05,
      "loss": 0.0256,
      "step": 950
    },
    {
      "epoch": 6.028257456828886,
      "grad_norm": 0.15370573103427887,
      "learning_rate": 4.066975412877255e-05,
      "loss": 0.0047,
      "step": 960
    },
    {
      "epoch": 6.0910518053375196,
      "grad_norm": 0.01013697125017643,
      "learning_rate": 3.959367866807926e-05,
      "loss": 0.0005,
      "step": 970
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 0.3803333640098572,
      "learning_rate": 3.852261854607866e-05,
      "loss": 0.0127,
      "step": 980
    },
    {
      "epoch": 6.216640502354788,
      "grad_norm": 0.5182034969329834,
      "learning_rate": 3.7457089961444636e-05,
      "loss": 0.0012,
      "step": 990
    },
    {
      "epoch": 6.279434850863423,
      "grad_norm": 0.03209717944264412,
      "learning_rate": 3.6397606446920294e-05,
      "loss": 0.0079,
      "step": 1000
    },
    {
      "epoch": 6.279434850863423,
      "eval_loss": 0.1341901272535324,
      "eval_runtime": 4.3177,
      "eval_samples_per_second": 12.043,
      "eval_steps_per_second": 12.043,
      "step": 1000
    },
    {
      "epoch": 6.342229199372056,
      "grad_norm": 1.6120167970657349,
      "learning_rate": 3.534467862182008e-05,
      "loss": 0.0015,
      "step": 1010
    },
    {
      "epoch": 6.405023547880691,
      "grad_norm": 0.017776479944586754,
      "learning_rate": 3.4298813945936295e-05,
      "loss": 0.0011,
      "step": 1020
    },
    {
      "epoch": 6.467817896389325,
      "grad_norm": 0.007994081825017929,
      "learning_rate": 3.3260516474968285e-05,
      "loss": 0.0018,
      "step": 1030
    },
    {
      "epoch": 6.530612244897959,
      "grad_norm": 0.984660267829895,
      "learning_rate": 3.223028661759211e-05,
      "loss": 0.0015,
      "step": 1040
    },
    {
      "epoch": 6.593406593406593,
      "grad_norm": 0.006792094558477402,
      "learning_rate": 3.12086208942881e-05,
      "loss": 0.0048,
      "step": 1050
    },
    {
      "epoch": 6.656200941915228,
      "grad_norm": 0.024966375902295113,
      "learning_rate": 3.019601169804216e-05,
      "loss": 0.016,
      "step": 1060
    },
    {
      "epoch": 6.718995290423862,
      "grad_norm": 0.9084259867668152,
      "learning_rate": 2.919294705703647e-05,
      "loss": 0.0007,
      "step": 1070
    },
    {
      "epoch": 6.781789638932496,
      "grad_norm": 0.00327309756539762,
      "learning_rate": 2.819991039944363e-05,
      "loss": 0.0003,
      "step": 1080
    },
    {
      "epoch": 6.84458398744113,
      "grad_norm": 0.005971861537545919,
      "learning_rate": 2.7217380320437978e-05,
      "loss": 0.0051,
      "step": 1090
    },
    {
      "epoch": 6.9073783359497645,
      "grad_norm": 0.1253233551979065,
      "learning_rate": 2.624583035153609e-05,
      "loss": 0.0009,
      "step": 1100
    },
    {
      "epoch": 6.970172684458399,
      "grad_norm": 0.0021719816140830517,
      "learning_rate": 2.5285728732377613e-05,
      "loss": 0.0001,
      "step": 1110
    },
    {
      "epoch": 7.032967032967033,
      "grad_norm": 0.050496701151132584,
      "learning_rate": 2.4337538185056762e-05,
      "loss": 0.0009,
      "step": 1120
    },
    {
      "epoch": 7.0957613814756675,
      "grad_norm": 0.0034934496507048607,
      "learning_rate": 2.3401715691112746e-05,
      "loss": 0.0005,
      "step": 1130
    },
    {
      "epoch": 7.158555729984301,
      "grad_norm": 0.006716188043355942,
      "learning_rate": 2.247871227128709e-05,
      "loss": 0.0001,
      "step": 1140
    },
    {
      "epoch": 7.221350078492936,
      "grad_norm": 0.0009888125350698829,
      "learning_rate": 2.1568972768153556e-05,
      "loss": 0.0001,
      "step": 1150
    },
    {
      "epoch": 7.28414442700157,
      "grad_norm": 0.019243506714701653,
      "learning_rate": 2.067293563172581e-05,
      "loss": 0.0,
      "step": 1160
    },
    {
      "epoch": 7.346938775510204,
      "grad_norm": 0.00930618867278099,
      "learning_rate": 1.9791032708145963e-05,
      "loss": 0.0001,
      "step": 1170
    },
    {
      "epoch": 7.409733124018838,
      "grad_norm": 0.0007748941425234079,
      "learning_rate": 1.8923689031555697e-05,
      "loss": 0.0093,
      "step": 1180
    },
    {
      "epoch": 7.472527472527473,
      "grad_norm": 0.0017268393421545625,
      "learning_rate": 1.807132261925073e-05,
      "loss": 0.0001,
      "step": 1190
    },
    {
      "epoch": 7.535321821036106,
      "grad_norm": 0.0028962192591279745,
      "learning_rate": 1.7234344270216713e-05,
      "loss": 0.0003,
      "step": 1200
    },
    {
      "epoch": 7.598116169544741,
      "grad_norm": 0.022106464952230453,
      "learning_rate": 1.6413157367144354e-05,
      "loss": 0.0001,
      "step": 1210
    },
    {
      "epoch": 7.660910518053376,
      "grad_norm": 0.002341190120205283,
      "learning_rate": 1.5608157682018505e-05,
      "loss": 0.0001,
      "step": 1220
    },
    {
      "epoch": 7.723704866562009,
      "grad_norm": 0.006609340198338032,
      "learning_rate": 1.4819733185375534e-05,
      "loss": 0.0001,
      "step": 1230
    },
    {
      "epoch": 7.786499215070644,
      "grad_norm": 0.0013273489894345403,
      "learning_rate": 1.4048263859320344e-05,
      "loss": 0.0,
      "step": 1240
    },
    {
      "epoch": 7.849293563579278,
      "grad_norm": 0.07831442356109619,
      "learning_rate": 1.3294121514393637e-05,
      "loss": 0.0001,
      "step": 1250
    },
    {
      "epoch": 7.912087912087912,
      "grad_norm": 0.0009170327102765441,
      "learning_rate": 1.2557669610377399e-05,
      "loss": 0.0,
      "step": 1260
    },
    {
      "epoch": 7.974882260596546,
      "grad_norm": 0.0032188063487410545,
      "learning_rate": 1.1839263081124946e-05,
      "loss": 0.0,
      "step": 1270
    },
    {
      "epoch": 8.03767660910518,
      "grad_norm": 0.0012005817843601108,
      "learning_rate": 1.113924816350026e-05,
      "loss": 0.0,
      "step": 1280
    },
    {
      "epoch": 8.100470957613815,
      "grad_norm": 0.0004258219269104302,
      "learning_rate": 1.04579622305086e-05,
      "loss": 0.0,
      "step": 1290
    },
    {
      "epoch": 8.16326530612245,
      "grad_norm": 0.009204444475471973,
      "learning_rate": 9.795733628699333e-06,
      "loss": 0.0,
      "step": 1300
    },
    {
      "epoch": 8.226059654631083,
      "grad_norm": 0.0023654152173548937,
      "learning_rate": 9.152881519918787e-06,
      "loss": 0.0,
      "step": 1310
    },
    {
      "epoch": 8.288854003139717,
      "grad_norm": 0.008465779945254326,
      "learning_rate": 8.529715727489912e-06,
      "loss": 0.0,
      "step": 1320
    },
    {
      "epoch": 8.351648351648352,
      "grad_norm": 0.002695883857086301,
      "learning_rate": 7.926536586892591e-06,
      "loss": 0.0,
      "step": 1330
    },
    {
      "epoch": 8.414442700156986,
      "grad_norm": 0.0016811956884339452,
      "learning_rate": 7.3436348010165025e-06,
      "loss": 0.0,
      "step": 1340
    },
    {
      "epoch": 8.47723704866562,
      "grad_norm": 0.0647282525897026,
      "learning_rate": 6.781291300056647e-06,
      "loss": 0.0,
      "step": 1350
    },
    {
      "epoch": 8.540031397174253,
      "grad_norm": 0.0008525348384864628,
      "learning_rate": 6.239777106118605e-06,
      "loss": 0.0,
      "step": 1360
    },
    {
      "epoch": 8.602825745682889,
      "grad_norm": 0.03304874897003174,
      "learning_rate": 5.719353202599209e-06,
      "loss": 0.0,
      "step": 1370
    },
    {
      "epoch": 8.665620094191523,
      "grad_norm": 0.00035867001861333847,
      "learning_rate": 5.220270408405198e-06,
      "loss": 0.0,
      "step": 1380
    },
    {
      "epoch": 8.728414442700156,
      "grad_norm": 0.0013237455859780312,
      "learning_rate": 4.7427692570708445e-06,
      "loss": 0.0,
      "step": 1390
    },
    {
      "epoch": 8.791208791208792,
      "grad_norm": 0.0008962669526226819,
      "learning_rate": 4.287079880832478e-06,
      "loss": 0.0,
      "step": 1400
    },
    {
      "epoch": 8.854003139717426,
      "grad_norm": 0.002238989109173417,
      "learning_rate": 3.853421899715992e-06,
      "loss": 0.0,
      "step": 1410
    },
    {
      "epoch": 8.91679748822606,
      "grad_norm": 0.0035400367341935635,
      "learning_rate": 3.44200431569075e-06,
      "loss": 0.0,
      "step": 1420
    },
    {
      "epoch": 8.979591836734693,
      "grad_norm": 0.0017506901640444994,
      "learning_rate": 3.053025411940802e-06,
      "loss": 0.0,
      "step": 1430
    },
    {
      "epoch": 9.042386185243329,
      "grad_norm": 0.0012774274218827486,
      "learning_rate": 2.6866726573021026e-06,
      "loss": 0.0,
      "step": 1440
    },
    {
      "epoch": 9.105180533751962,
      "grad_norm": 0.0023393691517412663,
      "learning_rate": 2.3431226159116637e-06,
      "loss": 0.0,
      "step": 1450
    },
    {
      "epoch": 9.167974882260596,
      "grad_norm": 0.0009377158712595701,
      "learning_rate": 2.022540862112282e-06,
      "loss": 0.0,
      "step": 1460
    },
    {
      "epoch": 9.23076923076923,
      "grad_norm": 0.01653391122817993,
      "learning_rate": 1.725081900653791e-06,
      "loss": 0.0,
      "step": 1470
    },
    {
      "epoch": 9.293563579277865,
      "grad_norm": 0.001211414230056107,
      "learning_rate": 1.4508890922293018e-06,
      "loss": 0.0,
      "step": 1480
    },
    {
      "epoch": 9.3563579277865,
      "grad_norm": 0.0041804239153862,
      "learning_rate": 1.2000945843823551e-06,
      "loss": 0.0,
      "step": 1490
    },
    {
      "epoch": 9.419152276295133,
      "grad_norm": 0.009692639112472534,
      "learning_rate": 9.728192478182574e-07,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 9.419152276295133,
      "eval_loss": 0.18522657454013824,
      "eval_runtime": 4.1604,
      "eval_samples_per_second": 12.499,
      "eval_steps_per_second": 12.499,
      "step": 1500
    },
    {
      "epoch": 9.481946624803768,
      "grad_norm": 0.0004415260045789182,
      "learning_rate": 7.691726181503267e-07,
      "loss": 0.0,
      "step": 1510
    },
    {
      "epoch": 9.544740973312402,
      "grad_norm": 0.0008102690917439759,
      "learning_rate": 5.892528431090393e-07,
      "loss": 0.0,
      "step": 1520
    },
    {
      "epoch": 9.607535321821036,
      "grad_norm": 0.0011902728583663702,
      "learning_rate": 4.331466352396396e-07,
      "loss": 0.0,
      "step": 1530
    },
    {
      "epoch": 9.67032967032967,
      "grad_norm": 0.005795539356768131,
      "learning_rate": 3.009292301109412e-07,
      "loss": 0.0,
      "step": 1540
    },
    {
      "epoch": 9.733124018838305,
      "grad_norm": 0.0005122036673128605,
      "learning_rate": 1.9266435005540483e-07,
      "loss": 0.0,
      "step": 1550
    },
    {
      "epoch": 9.795918367346939,
      "grad_norm": 0.001064139767549932,
      "learning_rate": 1.0840417345814313e-07,
      "loss": 0.0,
      "step": 1560
    },
    {
      "epoch": 9.858712715855573,
      "grad_norm": 0.0004551603051368147,
      "learning_rate": 4.818930960945878e-08,
      "loss": 0.0,
      "step": 1570
    },
    {
      "epoch": 9.921507064364206,
      "grad_norm": 0.00929179135710001,
      "learning_rate": 1.2048779133150279e-08,
      "loss": 0.0,
      "step": 1580
    },
    {
      "epoch": 9.984301412872842,
      "grad_norm": 0.0012520584277808666,
      "learning_rate": 0.0,
      "loss": 0.0,
      "step": 1590
    },
    {
      "epoch": 9.984301412872842,
      "step": 1590,
      "total_flos": 7.996688562473533e+17,
      "train_loss": 0.10339999800881462,
      "train_runtime": 8147.0559,
      "train_samples_per_second": 6.251,
      "train_steps_per_second": 0.195
    }
  ],
  "logging_steps": 10,
  "max_steps": 1590,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.996688562473533e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
